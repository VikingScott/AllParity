"""
================================================================================
ğŸ“œ DESIGN REQUIREMENTS
================================================================================
1. [Interaction]: Auto-detect common date range.
2. [Simulation]: Inject transaction costs & rebalancing frequency via Config.
3. [Reporting]: 
   - Dynamic Folder Naming (based on strategies).
   - Terminal Summary Table (CAGR, Sharpe, Vol, MaxDD).
   - CSV Outputs: Annual, Monthly, Rolling, AND Daily Matrix.
================================================================================
"""

import warnings
# [å…³é”®] å…¨å±€é™éŸ³ï¼šå±è”½ FutureWarning (fillna, downcasting)
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

# Path Hack
sys.path.append(str(Path(__file__).resolve().parent.parent))

from src.core.data import DataLoader
from src.strategy.simple_ma import SimpleMAStrategy
from src.backtester.engine import BacktestEngine
from src.backtester.config import BacktestConfig
from src.analysis.metrics import PerformanceMetrics
from src.analysis.rolling import RollingAnalyzer 
from src.analysis.reporting import ReportGenerator

# ============================================================
# 1. ğŸ”¬ RESEARCH CONFIGURATION (åœ¨æ­¤å¤„ä¿®æ”¹é…ç½®)
# ============================================================

SCENARIOS = [
    {
        "name": "MA200_LowCost",
        "strategy": SimpleMAStrategy(['SPY', 'TLT', 'GLD']),
        "config": BacktestConfig(
            transaction_cost=0.0005, 
            rebalance_freq='Signal'
        )
    },
    {
        "name": "MA200_HighCost",
        "strategy": SimpleMAStrategy(['SPY', 'TLT', 'GLD']),
        "config": BacktestConfig(
            transaction_cost=0.0020, # 20bps
            rebalance_freq='1D'      # æ¯æ—¥å¼ºå¹³
        )
    },
    {
        "name": "Tech_Drift",
        "strategy": SimpleMAStrategy(['QQQ', 'SMH']),
        "config": BacktestConfig(
            transaction_cost=0.0005,
            rebalance_freq='Drift_0.05'
        )
    }
]

CUSTOM_START_DATE = "2005-01-01" 
CUSTOM_END_DATE = None 

# ============================================================
# 2. HELPER FUNCTIONS
# ============================================================

def get_valid_date_range(strategies):
    print("ğŸ” Scanning Data Availability...")
    all_tickers = set(['SPY', 'AGG', 'IEF']) 
    for s in strategies:
        all_tickers.update(s.tickers)
    
    try:
        full_data = DataLoader.load_returns()
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        return None, None

    existing_tickers = [t for t in all_tickers if t in full_data.columns]
    if not existing_tickers:
        print("âŒ Critical: No tickers found in dataset!")
        return None, None
        
    subset = full_data[existing_tickers].dropna()
    if subset.empty:
        print("âŒ No overlapping data found.")
        return None, None
        
    min_date = subset.index[0].date()
    max_date = subset.index[-1].date()
    
    print(f"ğŸ”— Max Common Range: {min_date} to {max_date}")
    return str(min_date), str(max_date)

def print_terminal_summary(results, bench_rets):
    """
    [æ–°å¢éœ€æ±‚ 1] åœ¨ç»ˆç«¯æ‰“å°æ¼‚äº®çš„æ±‡æ€»è¡¨
    """
    print("\n" + "="*65)
    print("ğŸ“Š FINAL PERFORMANCE SUMMARY")
    print("="*65)
    
    summary_data = []
    
    # 1. Add Benchmark
    m_b = PerformanceMetrics(bench_rets)
    summary_data.append({
        "Strategy": "Benchmark (60/40)",
        "CAGR": f"{m_b.cagr():.2%}",
        "Sharpe": f"{m_b.sharpe():.2f}",
        "Vol": f"{m_b.volatility():.2%}",
        "MaxDD": f"{m_b.max_drawdown():.2%}",
        "Final($1k)": f"${m_b.final_value(1000):,.0f}"
    })
    
    # 2. Add Strategies
    for name, rets in results.items():
        m_s = PerformanceMetrics(rets)
        summary_data.append({
            "Strategy": name,
            "CAGR": f"{m_s.cagr():.2%}",
            "Sharpe": f"{m_s.sharpe():.2f}",
            "Vol": f"{m_s.volatility():.2%}",
            "MaxDD": f"{m_s.max_drawdown():.2%}",
            "Final($1k)": f"${m_s.final_value(1000):,.0f}"
        })
        
    df = pd.DataFrame(summary_data)
    # è®¾ç½®æ‰“å°æ ¼å¼ï¼Œä¸çœç•¥åˆ—
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 1000)
    # å·¦å¯¹é½ Strategy åˆ—
    print(df.to_string(index=False, justify='left'))
    print("="*65 + "\n")

# ============================================================
# 3. MAIN EXECUTION
# ============================================================

def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # [æ–°å¢éœ€æ±‚ 2] æ™ºèƒ½æ–‡ä»¶å¤¹å‘½å
    # æå–ç­–ç•¥åï¼Œç”¨ä¸‹åˆ’çº¿è¿æ¥ï¼Œå¤ªé•¿å°±æˆªæ–­
    strat_names = [s['name'] for s in SCENARIOS]
    name_str = "_".join(strat_names)
    if len(name_str) > 50: name_str = name_str[:50] + "..."
    
    folder_name = f"batch_{timestamp}_{name_str}"
    report_dir = Path(__file__).resolve().parent.parent / "reports" / "data" / folder_name
    report_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸš€ RESEARCH RUNNER")
    print(f"ğŸ“‚ Output Dir: {folder_name}")
    
    # 1. Timeframe
    all_strats_obj = [s['strategy'] for s in SCENARIOS]
    auto_start, auto_end = get_valid_date_range(all_strats_obj)
    if not auto_start: return

    start_date = CUSTOM_START_DATE if CUSTOM_START_DATE else auto_start
    end_date = CUSTOM_END_DATE if CUSTOM_END_DATE else auto_end
    
    print(f"ğŸ“… Range: {start_date} to {end_date}")

    # 2. Init Engine
    engine = BacktestEngine(start_date, end_date)
    
    # 3. Benchmark
    bench_rets = engine.run_benchmark_6040()
    if bench_rets.empty: return

    # 4. Run Scenarios
    results = {}
    for sc in SCENARIOS:
        name = sc['name']
        strat = sc['strategy']
        cfg = sc['config']
        
        rets = engine.run_strategy(strat, name=name, config=cfg)
        
        # ç®€å•æœ‰æ•ˆæ€§æ£€æŸ¥
        if not rets.empty and rets.std() > 0:
            common = rets.index.intersection(bench_rets.index)
            results[name] = rets.loc[common]

    if not results:
        print("âŒ No valid results.")
        return

    # Align Bench
    primary_idx = results[list(results.keys())[0]].index
    bench_rets = bench_rets.loc[primary_idx]

    # 5. Generate Reports (Delegated to ReportGenerator)
    # è¿™é‡Œæˆ‘ä»¬åªä¿ç•™æœ€å¤æ‚çš„ Annual/Rolling CSV ç”Ÿæˆ
    reporter = ReportGenerator(report_dir)
    reporter.save_all(results, bench_rets)
    
    # [æ–°å¢éœ€æ±‚ 3] Daily Returns Matrix
    # è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åŸå§‹æ•°æ®æ–‡ä»¶
    print("ğŸ“ Saving Daily Returns Matrix...")
    daily_dfs = [bench_rets.rename("Benchmark")]
    for name, rets in results.items():
        daily_dfs.append(rets.rename(name))
    
    df_daily = pd.concat(daily_dfs, axis=1)
    df_daily.to_csv(report_dir / "daily_returns_matrix.csv")
    print("âœ… Saved daily_returns_matrix.csv")

    # [æ–°å¢éœ€æ±‚ 1] Terminal Summary
    print_terminal_summary(results, bench_rets)

    print(f"ğŸ‰ Done. Reports in: {report_dir}")

if __name__ == "__main__":
    main()