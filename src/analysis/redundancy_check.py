import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
PROJECT_ROOT = Path(__file__).parent.parent.parent
RETURNS_PATH = PROJECT_ROOT / "data" / "processed" / "asset_returns.csv"
PRICES_PATH = PROJECT_ROOT / "data" / "processed" / "asset_prices.csv"
RAW_DIR = PROJECT_ROOT / "data" / "raw" / "daily" # ç”¨æ¥æŸ¥ Volume

# åˆ¤å®šä¸ºâ€œä¸€æ¨¡ä¸€æ ·â€çš„ç›¸å…³æ€§é˜ˆå€¼
CORR_THRESHOLD = 0.99

class RedundancyAnalyzer:
    def __init__(self):
        self.returns = self.load_data(RETURNS_PATH)
        self.prices = self.load_data(PRICES_PATH)
        self.meta_cache = {} # ç¼“å­˜ Start Date å’Œ Volume

    def load_data(self, path):
        if not path.exists():
            print(f"âŒ File not found: {path}")
            return pd.DataFrame()
        return pd.read_csv(path, index_col=0, parse_dates=True)

    def get_asset_stats(self, ticker):
        """è·å–èµ„äº§çš„å…ƒæ•°æ®ï¼šå¼€å§‹æ—¶é—´ï¼Œå¹³å‡æˆäº¤é‡"""
        if ticker in self.meta_cache:
            return self.meta_cache[ticker]

        # 1. Start Date (ä» Prices çŸ©é˜µç›´æ¥è·å–)
        valid_idx = self.prices[ticker].first_valid_index()
        start_date = valid_idx if valid_idx else datetime.now()
        
        # 2. Avg Volume (éœ€è¦å»è¯»åŸå§‹ Raw CSVï¼Œå› ä¸º Processed é‡Œæ²¡å­˜ Volume)
        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„è¿‘ä¼¼ï¼šè¯»å– raw æ–‡ä»¶æœ€å 30 è¡Œ
        avg_vol = 0
        raw_path = RAW_DIR / f"{ticker}.csv"
        if raw_path.exists():
            try:
                df = pd.read_csv(raw_path)
                if 'Volume' in df.columns and not df.empty:
                    avg_vol = df['Volume'].tail(30).mean()
            except:
                pass
        
        stats = {
            'start_date': start_date,
            'volume': avg_vol
        }
        self.meta_cache[ticker] = stats
        return stats

    def calculate_beta(self, series_target, series_benchmark):
        """è®¡ç®—ç›¸å¯¹ Beta"""
        # å¯¹é½æ•°æ®
        common = pd.concat([series_target, series_benchmark], axis=1).dropna()
        if common.empty: return 0
        
        cov = common.cov().iloc[0, 1]
        var = common.iloc[:, 1].var()
        if var == 0: return 0
        return cov / var

    def run(self):
        if self.returns.empty: return
        
        print("="*60)
        print(f"ğŸ” ASSET REDUNDANCY CHECKER (Threshold: {CORR_THRESHOLD})")
        print("="*60)
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        # è¿™é‡Œä½¿ç”¨æœ€è¿‘ 3 å¹´çš„æ•°æ®æ¥è®¡ç®—ç›¸å…³æ€§ï¼Œæ›´èƒ½åæ˜ å½“ä¸‹çš„æ›¿ä»£å…³ç³»
        # å¦‚æœå†å²å¤ªé•¿ï¼Œæ—©æœŸçš„æ•°æ®å¯èƒ½ä¼šç¨€é‡Šç°åœ¨çš„ç›¸å…³æ€§
        recent_returns = self.returns.tail(252 * 3) 
        corr_matrix = recent_returns.corr()
        
        columns = corr_matrix.columns
        duplicates = []
        dropped_set = set() # é˜²æ­¢ A-B å’Œ B-A é‡å¤æŠ¥å‘Š
        
        print(f"Analyzing {len(columns)} assets for identical pairs...\n")

        for i in range(len(columns)):
            for j in range(i + 1, len(columns)):
                ticker_a = columns[i]
                ticker_b = columns[j]
                
                corr_val = corr_matrix.iloc[i, j]
                
                if corr_val >= CORR_THRESHOLD:
                    # å‘ç°é«˜åº¦ç›¸å…³å¯¹ï¼
                    stats_a = self.get_asset_stats(ticker_a)
                    stats_b = self.get_asset_stats(ticker_b)
                    
                    # è®¡ç®— Beta (ä»¥ B ä¸ºåŸºå‡†çœ‹ A)
                    beta = self.calculate_beta(recent_returns[ticker_a], recent_returns[ticker_b])
                    
                    # å†³ç­–é€»è¾‘ï¼šè°è€è°ç•™ä¸‹
                    date_a = stats_a['start_date']
                    date_b = stats_b['start_date']
                    
                    keep = None
                    drop = None
                    reason = ""
                    
                    if date_a < date_b:
                        keep, drop = ticker_a, ticker_b
                        reason = f"Older history ({date_a.date()} vs {date_b.date()})"
                    elif date_b < date_a:
                        keep, drop = ticker_b, ticker_a
                        reason = f"Older history ({date_b.date()} vs {date_a.date()})"
                    else:
                        # å†å²ä¸€æ ·é•¿ï¼Œæ¯”æµåŠ¨æ€§
                        if stats_a['volume'] > stats_b['volume']:
                            keep, drop = ticker_a, ticker_b
                            reason = "Higher liquidity"
                        else:
                            keep, drop = ticker_b, ticker_a
                            reason = "Higher liquidity"
                    
                    duplicates.append({
                        'Keep': keep,
                        'Drop': drop,
                        'Corr': corr_val,
                        'Beta': beta,
                        'Reason': reason
                    })

        # è¾“å‡ºæŠ¥å‘Š
        if not duplicates:
            print("âœ… No redundant assets found. Your universe is clean!")
        else:
            print(f"âš ï¸ Found {len(duplicates)} pairs of highly identical assets:\n")
            print(f"{'KEEP':<10} | {'DROP':<10} | {'CORR':<6} | {'BETA':<6} | {'REASON'}")
            print("-" * 65)
            
            # ç®€å•çš„å»é‡å±•ç¤ºï¼šå¦‚æœä¸€ä¸ªèµ„äº§è¢«å»ºè®®åˆ é™¤å¤šæ¬¡ï¼Œåªæ˜¾ç¤ºä¸€æ¬¡
            # è¿™é‡Œçš„é€»è¾‘æ¯”è¾ƒç®€å•ï¼Œåªæ˜¯å±•ç¤ºå»ºè®®
            for item in duplicates:
                print(f"{item['Keep']:<10} | {item['Drop']:<10} | {item['Corr']:.4f} | {item['Beta']:.2f}   | {item['Reason']}")

            print("\n" + "="*60)
            print("ğŸ’¡ ACTION PLAN:")
            unique_drops = set(d['Drop'] for d in duplicates)
            print(f"You can safely remove these {len(unique_drops)} tickers from your config:")
            print(", ".join(sorted(list(unique_drops))))
            print("="*60)

if __name__ == "__main__":
    analyzer = RedundancyAnalyzer()
    analyzer.run()